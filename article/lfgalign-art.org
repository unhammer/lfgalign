#+TITLE: Automatic Constituent and Function Alignment for Parallel Treebanking
#+STARTUP: hidestars
#+SEQ_TODO: ULEST SKRIV FERDIG
#+AUTHOR: 
#Kevin Brubeck Unhammer
#+EMAIL: 
#Kevin.Unhammer hos student uib no
#+LANGUAGE: en
#+OPTIONS: H:4 toc:nil f:t skip:nil num:t
#+LaTeX_CLASS: TLT
#+LaTeX_HEADER: \newcommand{\ind}[1]{{\avmoptions{}\begin{avm}\@{#1}\end{avm}}}
#+LaTeX_HEADER: \newcommand{\xbar}{$\rm\overline{X}$}
#+LaTeX_HEADER: \newcommand{\F}[2]{\textsc{#1}\ensuremath{_{#2}}}
#+LaTeX_HEADER: \newcommand{\OBLben}{\F{obl}{ben}}
#+LaTeX_HEADER: \newcommand{\OBJben}{\F{obj}{ben}}
#+LaTeX_HEADER: \newcommand{\OBJ}{\F{obj}{}}
#+LaTeX_HEADER: \newcommand{\OBJs}{\F{obj~}{}}
#+LaTeX_HEADER: \newcommand{\ADJ}{\F{adj}{}}
#+LaTeX_HEADER: \newcommand{\ADJUNCT}{\F{adjunct}{}}
#+LaTeX_HEADER: \newcommand{\ADJs}{\F{adj~}{}}
#+LaTeX_HEADER: \newcommand{\XCOMP}{\F{xcomp}{}}
#+LaTeX_HEADER: \newcommand{\XCOMPs}{\F{xcomp~}{}}
#+LaTeX_HEADER: \newcommand{\SUBJ}{\F{subj}{}}
#+LaTeX_HEADER: \newcommand{\SUBJs}{\F{subj~}{}}
#+LaTeX_HEADER: \newcommand{\PRED}{\F{pred}{}}
#+LaTeX_HEADER: \newcommand{\TOPIC}{\F{topic}{}}
#+LaTeX_HEADER: \newcommand{\falign}{\ensuremath{\operatorname{\emph{falign}}}}
#+LaTeX_HEADER: \newcommand{\fpairs}{\ensuremath{\operatorname{\emph{fpairs}}}}
#+LaTeX_HEADER: \newcommand{\Bleu}{\textsc{Bleu}}
#+LaTeX_HEADER: \usetikzlibrary{calc}
#+LaTeX_HEADER: \newcommand{\proj}[2]{\begin{tabular}{c}\footnotesize{#1}\\\normalsize{#2}\end{tabular}}
#+LaTeX_HEADER: \newcommand{\ua}{\ensuremath{\uparrow}}
#+LaTeX_HEADER: \newcommand{\da}{\ensuremath{\downarrow}}

\begin{abstract}
\noindent
This paper describes the development of an automatic phrase alignment
 method using parallel sentences parsed in Lexical-Functional Grammar
 as input, where similarity in analyses is used as evidence that
 constituents or functional elements \fxnote[inline,nomargin]{vil seie
 «f-struktur-element», men slik at ikkje-LFG-folk forstår det} may be
 linked. A set of principles for phrase alignment are formulated,
 based on the goals of the XPar-project \cite{dyvik2009lmp}, and an
 implementation is given.
\end{abstract}

\thispagestyle{empty}


* Introduction
Lexical-Functional Grammar (LFG) is a grammatical framework where a
 sentence is analysed as having both a constituent structure
 (c-structure) and functional structure (f-structure). The former is
 similar to traditional phrase structure trees, while the latter is an
 attribute-value matrix/graph which represents dependency relations
 between syntactic functions (subject, object, etc.), in addition to
 the grammatical features of these. The argument structure of
 predicates is embedded in the f-structure representation.

This work is part of the XPar-project, which involves developing a
 parallel treebank which will include links between corresponding
 constituents, as well as between corresponding syntactic
 functions. By utilising the information available in each monolingual
 LFG-parse of two parallel sentences, we are able to make precise and
 linguistically informative alignments on both the c-structure and
 f-structure level.

Although there exists many methods for automatic phrase alignment
 \cite{och2003scv}, most of these have been based on aligning any
 N-gram that is compatible with a word alignment, where none of these
 take into account syntactic features, and alignments may cross
 constituent borders. \cite{hearne2008ccd} describes a method for using
 statistical word-alignments as seeds to two separate constituent and
 dependency tree alignments; however, the goal here is to create a set
 of N-gram pairs for statistical machine translation, and the
 dependency and constituent alignments do not inform each other.

Our method is instead based on the fact that similar grammatical
 phenomena in different languages should have similar grammatical
 analyses[fn:9], so structural similarity in the analyses should
 indicate that those parts of the analyses may be linked. How much
 structural similarity is required in order to link two elements is
 defined as a set of general constraints. This allows for a more
 top-down method of phrase alignment, which is more informative to the
 linguist since it links not only true constituents, but functional
 elements (which in LFG may even span discontiguous
 constituents). Word-alignments or translational dictionaries may be
 needed to automatically disambiguate in cases where the LFG parses do
 not give sufficient information; but the method will perform a large
 part of the alignment job even without /any/ parallel corpus
 available.

The principles and constraints for alignment are discussed in the next
 section, section \ref{SEC:implementation} describes the
 implementation, while section \ref{SEC:discussion} discusses the
 strengths and weaknesses of the method.

* Principles for Phrase Alignment
\label{SEC:principles}

We want our alignment links to be useful for treebank studies, in the
 XPar-project this includes studying the relationship between
 syntactic function and semantic roles across languages, thus the
 principles for alignment (or, constraints on possible alignments)
 have to take this goal into account.  An outline of the principles
 for phrase alignment used in the XPar-project are formulated in
 \cite[pp.~75--77]{dyvik2009lmp}, this section recounts the major
 points, and explains some relevant LFG-terminology and concepts.

# similar surroundings required, more?

To introduce the relevant LFG-terminology, consider figure
 \ref{fig:simple-links}. This shows two simplified LFG f-structures
 and c-structures, ready for alignment. The English word /slept/ is a
 verb phrase, and its nodes /project/ the f-structure $g$ (as seen by
 the \PRED{} value being the `semantic form' of /slept/,
 `\textbf{sleep}'). The projection from c-structure to f-structure,
 $\phi$, is a many-to-one mapping, and all the nodes S, VP and V
 together project $g$. Since the nodes project the same f-structure,
 they constitute a /functional domain/. We can see that they project
 the same f-structure by the $\ua{}=\da$ annotations, which are read
 as "my f-structure is the same as that of my mother node". The NP
 node has $\ua{}\SUBJ{}=\da$ instead, read as "my f-structure is the
 \SUBJ{} of my mother's f-structure"; the NP thus projects the value
 of the \SUBJ{} f-structure inside $g$.

The argument structures of the Norwegian and English verbs are shown
 in their \PRED{} values; both verbs take one argument, in the figure
 this is represented by an index. By looking up this index, we find
 that the one argument of `\textbf{sove}' is the subject of $f$, with
 `\textbf{eg}' as its \PRED{}; similarly `\textbf{I}', subject of $g$,
 is the only argument of `\textbf{sleep}'. Neither of these subjects
 take any arguments themselves.


The candidates we consider for alignment are c-structure phrases,
 individual words, and \PRED{} elements of f-structures[fn:1].  In
 figure \ref{fig:simple-links}, we can link the \PRED{} elements of
 $f$ and $g$; by doing this we consider their f-structures linked.
 The \PRED{} values of their arguments are also candidates for
 alignment, and in this case there would be no reason not to link
 them. As noted, the S, VP and V nodes in English constitute the
 functional domain of $g$, similarly IP, I' and V are the functional
 domain of $f$. Since their f-structures are linked, we have reason to
 link nodes from these functional domains. But we only want to link
 nodes if the material they dominate also corresponds: we would not
 want to link IP and S if the NP in Norwegian was linked to something
 that was not dominated by the S in English (or vice versa), since a
 c-structure link means that what is dominated by the linked nodes
 corresponds[fn:2]. However, translations often ommit or add material,
 so an /unlinked/ subordinate node (e.g. an adverbial only expressed
 in one language) should not interfere with the linking of IP and S.

#+BEGIN_LaTeX
 \begin{figure}[htp]
    \centering
    \begin{tikzpicture}
    {\avmoptions{}
     \node(src){
        \begin{avm}
          $f$ \[pred   &  `{\bf{}sove}<\@{1}>'\\
          tense  & pret  \\
	  subj & \@{1} \[pred & `{\bf{eg}}' \] \\
          ... \] 
       \end{avm}
      };
      \node[right of=src, node distance=5cm](trg){
        \begin{avm}
          $g$ \[pred   &  `{\bf{}sleep}<\@{2}>'\\
          tense  & pret  \\
          aspect & simple \\
	  subj & \@{2} \[pred & `{\bf{I}}' \] \\
          ... \]
        \end{avm}
      };
      }
%      \draw[dashed,-] (src.west) .. controls +(-1,3) and +(-1,2) .. node[above,sloped]{$l_f$} (trg.west) ;
%      \draw[-] ($(src.north)-(1,0.3)$) .. controls +(0,1.5) and +(0,1.5) .. node[above,sloped]{$l_p$} ($(trg.north)-(1,0.3)$) ;

      \begin{scope}[shift={(0,-2cm)}]
        \Tree  [.\node(VPs){IP}; [.\proj{\ua{}\SUBJ{}=\da}{NP} \edge[roof]; {eg} ] [.\proj{\ua{}=\da}{I'} [.\proj{\ua{}=\da}{V} \node(sov){sov};  ] ] ]
      \begin{scope}[shift={(5cm,0)}]
        \Tree  [.\node(VPt){S}; [.\proj{\ua{}\SUBJ{}=\da}{NP} \edge[roof]; {I} ] [.\proj{\ua{}=\da}{VP} [.\proj{\ua{}=\da}{V} \node(slept){slept};  ] ] ]
      \end{scope}
      \end{scope}
%      \draw[-] (VPs)..controls +(north:1.5) and +(north:1.5) .. node[above,sloped]{$l_c$} (VPt) ;
%      \draw[dashed,-] (sov)..controls +(north east:1.5) and +(north west:1.5) .. node[above,sloped]{$l_o$} (slept) ;
   \end{tikzpicture}
    
    \caption{Example of simple links between constituents,
   f-structures and words (Norwegian and English)}
   \label{fig:simple-links}
 \end{figure}
#+END_LaTeX

Similarly, on the f-structure level we allow adjuncts (adverbials) to
 remain unlinked; adjuncts differ from arguments mainly in being
 non-obligatory, while arguments /are/ required in order to express a
 certain sense of a predicate. So to link two predicates, we require
 all their arguments to find `linguistically predictable translations'
 (LPT) in the translation, where a source word $W_s$ is
 LPT-correspondent with a target word $W_t$ if "$W_t$ can in general
 (out of context) be taken to be among the semantically plausible
 translations of $W_s$" \cite[p.~74]{dyvik2009lmp}. Nouns and
 pronominal forms are also considered LPT-correspondent.

The argument structure of predicates in LFG is ordered, and this order
 typically reflects the semantic role hierarchy (agents being before
 themes, etc.). However, we do not require that linked arguments
 occupy the same positions in the argument structure of their
 predicates, since an English grammar may assign the first argument of
 the verb /like/ to the agent, while a Spanish grammar may assign the
 first argument of the translation, /gustar/, to the theme. As one of
 the goals of the XPar-project is to study the relationship between
 semantic role and syntactic function, the aligner cannot presume that
 the relationship always is straightforward. However, given
 insufficient information, similarity in order may be used to /rank/
 different possible f-structure alignments.

If any of the arguments of two otherwise linkable predicates do not
 have LPT-correspondents among each other, we have evidence that the
 predicates themselves are used to express different propositions. But
 should we allow adjuncts as translations of arguments?  The examples
 in \ref{ex:vedde} are all translations of the same sentence; for the
 four different different languages, the grammar writers chose four
 different ways of dividing the participants in the verbal situation
 into arguments and adjuncts[fn:3]. but in this translation, the
 predicates clearly express the same proposition.  Thus we have to
 allow linking arguments to adjuncts; the monolingual evidence which
 informed the individual grammars may have suggested that a certain
 participant of a verbal situation should be analysed as an argument
 in one language, but as an adjunct in the other -- in a particular
 translation, however, they may still correspond semantically.

#+BEGIN_LaTeX
{\avmoptions{}
\ex. \label{ex:vedde}
\a. Adams veddet en sigarett med Browne \hfill{} (Norwegian Bokmål)\\ på at det regnet.\\
    $\\\begin{avm}\[pred & `{\bf{}vedde}<Abrams, cigarette, Browne, rain>' \\
                 adjunct & \{\}\]\end{avm}\\$
\b. abramsi brouns daenajleva sigaretze, rom cvimda. \hfill{} (Georgian)\\
    $\\\begin{avm}\[pred &  `{\bf{}da-najleveba}<Abrams, Browne, regne>'\\
    adjunct &  \{ \rm cigarette \}\]\end{avm}\\$ 
\c. Abrams hat mit Browne um eine Zigarette gewettet, \hfill{}(German)\\
    daß es regnet.\\
    $\\\begin{avm}\[pred & `{\bf{}wetten}<Abrams, regne>' \\
                  adjunct & \{ \rm Browne, cigarette \}\]\end{avm}\\$
\d. Abrams bet a cigarette with Brown that it was raining. \hfill{}(English)\\
    $\\\begin{avm}\[pred & `{\bf{}bet}<Abrams, sigarett, regne>'\\
                  adjunct & \{ \rm Browne \}\]\end{avm}$

}
#+END_LaTeX


More formally, these are the requirements for linking two f-structure
\PRED{} elements $p$ and $q$: 
\ex. \label{krav:pred} \a. the word-forms of $p$ and $q$ have LPT-correspondence
     \b. all arguments of $p$ have LPT-correspondence with an argument
     or adjunct of $q$
     \c. all arguments of $q$ have LPT-correspondence with an argument
     or adjunct of $p$
     \d. the LPT-correspondences are one-to-one
     \e. no adjuncts of $p$ are linked to f-structures outside $q$ or
     vice versa

Additionally, when an argument/adjunct is selected by a preposition
 we skip the \PRED{} of the preposition and consider its object as if
 there were no preposition there.

The one-to-one requirement \Last[d] is there to avoid linking two
 near-synonyms in one language into one word in the other language. We
 require all arguments of $p$ to have possible translations among the
 arguments and adjuncts of $q$, but we do not require \Last to be true
 of each argument of $p$; that is, an argument of $p$ may remain
 unlinked on the f-structure level. 
As mentioned, for adjuncts of $p$ we do not even require that they
 have LPT-correspondence with arguments/adjuncts of $q$, or vice
 versa, but \Last[e] ensures that they are not /linked/ outside of
 their predicates, which would imply that $p$ and $q$ did not contain
 corresponding linked material.

In order to link two c-structure nodes, \cite[p.~77]{dyvik2009lmp}
 defines the term /linked lexical nodes/, $LL$, where $LL(n)$ is the
 set of nodes dominated by $n$ which are word-linked. To link $n_s$
 and $n_t$ (whose projected f-structures must be linked), all nodes in
 $LL(n_s)$ must be linked to nodes in $LL(n_t)$. Unlinked nodes
 dominated by $n_s$ or $n_t$ are not an obstacle to linking these
 nodes. Thus in in figure \ref{fig:simple-links}, if the NP nodes are
 linked, we may link IP and S.

Figure \ref{fig:roboter} shows a much more complex situation, here the
 Norwegian I' and lower Georgian IP node may not be linked since the
 IP node dominates /robotebze/, linked to /roboter/, which is outside
 the nodes dominated by I'[fn:6].  Georgian being a pro-drop language,
 the argument expressed by /de/ in Norwegian does not have to be
 overtly expressed in Georgian, so there is no c-structure link for
 this word[fn:5].  But by the criterion above we can still link the
 upper IP nodes, as they dominate the same sets of linked lexical
 nodes; the adjunct /gzaSi/ (``on the way'') is a translators addition
 only seen in the Georgian text, and remains unlinked both on
 c-structure and f-structure level, it does not stop linking the IP
 nodes.

#+BEGIN_LaTeX
    \begin{figure}[htp]
    \centering
      \begin{tikzpicture}
      \tikzset{level distance=1.5cm}
      \Tree  [.\node(IPs){IP};  [.\node(roboter){\proj{\ua{}\TOPIC{}=\da}{NP}}; \edge[roof]; {roboter} ]
                                [.\node(I's){\proj{\ua=\da}{I'}};
                                        [.\node(Is){\proj{\ua=\da}{I}}; {hadde} ]
                                        [.\node(Ss){\proj{\ua=\da}{S}};
					[.\node(SUBJs){\proj{\ua\SUBJ{}=\da}{NP}}; \edge[roof]; {de} ]
                                           [.\node(VPs){\proj{\ua{}\XCOMP{}=\da}{VP}};  
                                             [.\node(Vs){\proj{\ua=\da}{V}}; {snakket} ]
					     [.\node(om){\proj{}{PP}}; \edge[roof]; {om} ]
  ] ] ] ]
          \begin{scope}[shift={(2.7in,0in)}]
      \Tree  [.\node(IPt){IP};  [.\node(PPt){\proj{\da$\in$\ua{}\ADJUNCT{}}{PP}}; \edge[roof]; {gzaSi} ]
                                [.\node(IP2t){\proj{\ua=\da}{IP}};
                                        [.\node(roboteb){\proj{\da$\in$\ua{}\ADJUNCT{}}{PP}}; \edge[roof]; {robotebze} ]
                                        [.\node(I't){\proj{\ua=\da}{I'}}; \edge[roof]; {laparakobdnen} ]
  ] ]
    \end{scope}
  \draw[dashed,-] (I's)..controls +(north:2) and +(north:3) .. node[midway,sloped]{$\times$} (IP2t) ;
  \draw[-] (roboter)..controls +(north east:2.5) and +(west:2.0) ..  (roboteb) ;
%  \draw[dashed,-] (VPs)..controls +(east:1) and +(west:1) .. node[above,sloped]{?} (I't) ;
    
    \end{tikzpicture}
       \caption{C-structure links must dominate the same set of links
       (Norwegian Bokmål ``robots, had they talked about'' and
       Georgian ``on.the.way, about.robots they.had.talked'')}
       \label{fig:roboter}
      \end{figure}
#+END_LaTeX

By the above criterion, we may also link the Norwegian VP and Georgian
 I' nodes, since they dominate the same linked lexical nodes,
 /laparakobdnen/ and /snakket/. However, /laparakobdnen/ specifies a
 non-overt third person plural subject, while /snakket/ does not. On
 the f-structure level, this pro-subject is linked to the Norwegian
 subject (/de/ in the c-structure); a treebank user may want to
 exclude the link between the VP and I' nodes because of this
 discrepancy. Formally, we can exclude this kind of link by adding any
 linked f-structure arguments (of the f-structure projected by $n$)
 that are not overtly expressed, to $LL(n)$[fn:7].

Several nodes may have equal $LL$, thus the c-structure links are
 often /many-to-many/. In addition, the f-structure \PRED{} links are
 not always one-to-one, but this is a slightly more complex situation.

The f-structures of figure \ref{fig:roboter} need a many-to-many
 \PRED{} link from /hadde/ and /snakket/ to /laparakobdnen/, since the
 current XPar grammars analyse /laparakobdnen/ (they.had.talked) as a
 single predicate, while treating /hadde/ (the perfective auxiliary)
 and /snakket/ (talked) as two separate predicates. One might argue
 that then such phenomena should be analysed similarly, but as it is
 the goal of the aligner to help in discovering cross-language
 differences, all the while assuming that similar grammatical
 phenomena have similar grammatical analyses, grammars cannot be
 changed just to make the alignment easier -- we have to treat this as
 a many-to-one \PRED{} link[fn:10]. 

In order to many-to-one-link $p$ with $q$ and $a_q$ on the f-structure
 level, where $a_q$ is an argument of $q$, the same requirements as
 \ref{krav:pred} need to be fulfilled, but with the following
 difference: the argument lists of $q$ and $a_q$ are merged (as are
 their adjunct lists), with $a_q$ not appearing in this list. 

#+BEGIN_LaTeX
\begin{figure}[htp]
\centering
\begin{tikzpicture}
    {\avmoptions{}
     \node(src){
        \begin{avm}
    $q$ \[pred    &       `{\bf{}perf}<\@{1}>\@{2}'\\
	  subj    & \@{2} \\
	  topic   & \@{3} \\
	  xcomp   & \@{1} \[pred & `{\bf{snakke*om<\@{2},\@{3}>}}' \\
	                    subj & \@{2} \[pred & `{\bf{de}}' \] \\
                            obj  & \@{3} \[pred & `{\bf{robot}}' \]
		 	  \]
        \]
       \end{avm}
      };
      \node[below of=src, node distance=4cm](trg){
        \begin{avm}
    $p$ \[pred    &       `{\bf{laparaki}}<\@{4}>'\\
	  subj    & \@{4} \[pred & `{\bf{pro}}' \] \\
	  adjunct & \{ \[pred & `{\bf{Si<\@{5}>}}' \\
                         obj  & \@{5} \[pred & `{\bf{gza}}' \] \],
		       \[pred & `{\bf{ze<\@{6}>}}' \\
                         obj  & \@{6} \[pred & `{\bf{roboti}}' \] \] \}
        \]
        \end{avm}
      };
      }
\end{tikzpicture}
\caption{Example of many-to-one link in f-structure: \textbf{perf} and
\textbf{snakke*om} together link to \textbf{laparaki}.}
\label{fig:simple-links}
\end{figure}
#+END_LaTeX

So when attempting to link /hadde/ ($q$) and /snakket/ ($a_q$) with
 /laparakobdnen/ ($p$), we merge the argument lists of $q$ and its
 \XCOMP{} argument, excluding the \XCOMP{} itself, i.e.
 $\{\ind{1},\ind{2}\}\bigcup\{\ind{2},\ind{3}\}-\{\ind{1}\}=\{\ind{2},\ind{3}\}$
 (there are no adjuncts on the Norwegian side). Now we can link
 /laparakobdnen/ with /hadde/ and /snakket/ by matching /de/ (\ind{2})
 with the pro-element (\ind{4}), and /robot/ (\ind{3}) with
 /roboti/ (\ind{6}). 


The next section discusses the current implementation of these
principles, while section \ref{SEC:discussion} compares the possible
merits of this method with other alignment methods.


* Implementation
\label{SEC:implementation}

This section covers a work-in-progress implementation of the above
 alignment principles[fn:4]. The program takes as input LFG-analyses
 of two sentences which we have for independent reasons consider as
 translations of each other. The analyses must be disambiguated and in
 the Prolog-format from XLE[fn:8]. One may in addition give the
 program information about which word-translations are considered LPT,
 perhaps from automatic word-alignments or simple translational
 dictionaries.

The program begins by linking f-structures, where an f-structure
 /alignment/ is a set of /links/ between individual f-structures. The
 result of linking on this level may be ambiguous; since there are
 often several ways of linking arguments and adjuncts given
 insufficient LPT-information, we may end up with several possible
 f-structure alignments.

Therefore we rank the f-structure alignments. There are several
 possible ranking criteria, as mentioned above we use similarity in
 order of arguments to rank different possible f-structure alignments,
 when the LPT-information is not sufficient.

A single f-structure alignment is sent to the c-structure aligner,
 which by following the principles above always finds a single,
 unambiguous c-structure alignment (the different possible ways of
 calculating $LL$ noted above are considered a user-option). 

The f-structure aligner starts with the two outermost f-structures
 projected by LPT-correspondent words, and finds all possible ways of
 matching all arguments of the source \PRED{} with LPT-correspondent
 arguments/adjuncts of the target \PRED{} and vice versa (additionally
 adding any pairs of LPT-correspondent adjuncts that were not matched
 to arguments). For each of these possibilities, we recursively try to
 align the matched arguments/adjuncts[fn:11], storing these possible
 sub-alignments in a table since solutions may overlap.

If we find no possibility of f-structure alignment (no way of
 fulfilling the requirements in \ref{krav:pred} for the given \PRED{}
 elements), we may try many-to-one links by merging argument lists as
 discussed in the previous section. Since this is not tried until
 there are no other possibilities, solutions involving many-to-one
 links of \PRED{} elements are implicitly ranked lower than those
 where we can assume that translations corresponded better (a natural
 assumption since the sentences were aligned in the first place).

After ranking, finding the c-structure alignment for a single
 f-structure alignment is a simple matter of finding the $LL$ for each
 node (being the union of the $LL$ of each daughter node), and
 creating many-to-many links between those nodes that have the same
 $LL$. The many-to-many links here are the constituent alignment.

* Discussion and outlook
\label{SEC:discussion}


** Value over more corpus-based methods for lesser-resourced languages
No huge parallel corpus needed, given some manual intervention, not
even a translational dictionary is needed.

* Conclusion
# tom inndeling for å halde bibliografien sist

 

\bibliography{master}






* Footnotes

[fn:1] We could consider aligning other f-structure elements, but only
 \PRED{} elements are sure to exist in both languages, while
 grammatical features such as \F{ASPECT}{} might not exist in both
 languages, or be possible to link in a one-to-one-manner.

[fn:2] Even if IP and S could not be linked, we could still link I'
 and VP, as these dominate the same linked material.

[fn:3] The f-structures here are highly simplified.

[fn:4] All code available from http://example.com under the GNU
       General Public License, version 2 or later, along with some
       examples of input parses.

[fn:5] The pro-subjects will be linked in f-structure, however. 

[fn:6] The notation $\da\in\ua\ADJUNCT{}$ reads "my f-structure is a
 member of the set of adjuncts of my mother's f-structure" (a
 predicate may have only one subject, but an arbitrary number of
 adjuncts). Figure \ref{fig:roboter} is another example of phrases
 analysed as adjuncts in one language corresponding to phrases
 analysed as arguments in another language.

[fn:7] We cannot add just any /overtly/ expressed argument to $LL$, as
 that would let us link the Norwegian I' and the Georgian IP node.

[fn:8] http://www2.parc.com/isl/groups/nltt/xle/doc/xle.html

[fn:9] This is a basic tenet of the XPar-project.

[fn:10] Although in this case we might be able to align only the
 content verbs /hadde/ and /laparakobdnen/ by simply excluding
 auxiliary verbs from f-structure alignment, as with prepositions,
 there are other situations where we cannot avoid many-to-many links
 in a non-arbitrary fashion, e.g. lexical causatives linking to
 periphrastic causatives, argument incorporation, etc.

[fn:11] We allow \PRED{} elements $p$ and $q$ to be linked even though
 some of their arguments cannot be recursively \PRED{}-linked, as long
 as the requirement for word-level LPT-correspondence is fulfilled.



