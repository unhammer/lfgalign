#+TITLE: LFG-based Constituent and Function Alignment for Parallel Treebanking
#+STARTUP: hidestars
#+SEQ_TODO: ULEST SKRIV FERDIG
#+AUTHOR: 
#Kevin Brubeck Unhammer
#+EMAIL: 
#Kevin.Unhammer hos student uib no
#+LANGUAGE: en
#+OPTIONS: H:4 toc:nil f:t skip:nil num:t

#+LaTeX_CLASS: TLT

#+LaTeX_HEADER: \newcommand{\ind}[1]{{\avmoptions{}\begin{avm}\@{#1}\end{avm}}}
#+LaTeX_HEADER: \newcommand{\xbar}{$\rm\overline{X}$}
#+LaTeX_HEADER: \newcommand{\F}[2]{\textsc{#1}\ensuremath{_{#2}}}
#+LaTeX_HEADER: \newcommand{\OBLben}{\F{obl}{ben}}
#+LaTeX_HEADER: \newcommand{\OBJben}{\F{obj}{ben}}
#+LaTeX_HEADER: \newcommand{\OBJ}{\F{obj}{}}
#+LaTeX_HEADER: \newcommand{\OBJs}{\F{obj~}{}}
#+LaTeX_HEADER: \newcommand{\ADJ}{\F{adj}{}}
#+LaTeX_HEADER: \newcommand{\ASPECT}{\F{aspect}{}}
#+LaTeX_HEADER: \newcommand{\ADJUNCT}{\F{adjunct}{}}
#+LaTeX_HEADER: \newcommand{\ADJs}{\F{adj~}{}}
#+LaTeX_HEADER: \newcommand{\XCOMP}{\F{xcomp}{}}
#+LaTeX_HEADER: \newcommand{\XCOMPs}{\F{xcomp~}{}}
#+LaTeX_HEADER: \newcommand{\SUBJ}{\F{subj}{}}
#+LaTeX_HEADER: \newcommand{\SUBJs}{\F{subj~}{}}
#+LaTeX_HEADER: \newcommand{\PRED}{\F{pred}{}}
#+LaTeX_HEADER: \newcommand{\TOPIC}{\F{topic}{}}
#+LaTeX_HEADER: \newcommand{\falign}{\ensuremath{\operatorname{\emph{falign}}}}
#+LaTeX_HEADER: \newcommand{\fpairs}{\ensuremath{\operatorname{\emph{fpairs}}}}
#+LaTeX_HEADER: \newcommand{\Bleu}{\textsc{Bleu}}
#+LaTeX_HEADER: \newcommand{\proj}[2]{\begin{tabular}{c}\footnotesize{#1}\\\normalsize{#2}\end{tabular}}
#+LaTeX_HEADER: \newcommand{\ua}{\ensuremath{\uparrow}}
#+LaTeX_HEADER: \newcommand{\da}{\ensuremath{\downarrow}}

#+LaTeX_HEADER: \usetikzlibrary{calc}

#+LaTeX_HEADER: \avmfont{\footnotesize\sc}

#+BEGIN_LaTeX
\begin{abstract}
\noindent

This paper describes the development of an automatic phrase alignment
 method using as input parallel sentences parsed in Lexical-Functional
 Grammar, where similarity in analyses is used as evidence that
 constituents (syntactic phrases) or functional elements (predicates,
 arguments, adjuncts) may be linked. A set of principles for phrase
 alignment are formulated, with the goal of creating a parallel
 treebank for linguistic research, and an implementation is given.
\end{abstract}

\thispagestyle{empty}

\setlength{\Exlabelsep}{1.3em} % was 1.3em
\alignSubExtrue % wasn't
#+END_LaTeX

* COMMENT for final version:
\author{xxx % name
\\[0.5cm] uuu % university
\\addr % faculty
\\E-mail: \texttt{email}} % email

* Introduction
Lexical-Functional Grammar (LFG) is a grammatical framework where a
 sentence is analysed as having both a constituent structure
 (c-structure) and functional structure (f-structure). The former is
 similar to traditional phrase structure trees, while the latter is an
 attribute-value matrix/graph which represents functional relations
 between constituents (predicates and their subjects, objects, etc.),
 in addition to the grammatical features of these. The argument
 structure of predicates is embedded in the f-structure
 representation.

The work presented here is part of a master's thesis using resources
 from the XPar-project \cite{dyvik2009lmp}, which involves developing
 an LFG-parsed parallel treebank for Dutch, Tigrinya, Georgian and
 Norwegian, which will include links between corresponding
 constituents, as well as between corresponding syntactic functions.
 By utilising the information available in each
 monolingual LFG-parse of two parallel sentences in this treebank, we
 aim to create precise and linguistically informative alignments on
 both the c-structure and f-structure level.

Although there exist many methods for automatic phrase alignment, e.g.
 \cite{och2003scv}, most of these have been based on aligning any
 N-gram that is compatible with a word alignment, where syntactic
 features are not taken into account, and alignments may cross
 constituent borders. Later work has used statistical word-alignments
 as seeds to both constituent and dependency tree alignments,
 e.g. \cite{hearne2008ccd}, but the separate dependency and
 constituent alignments created here do not inform each other.
 Additionally, the goal has often been to create a set of N-gram pairs
 for statistical machine translation rather than a linguistically
 informative treebank; however, there has been newer research
 converting the output of these N-gram-based alignments into treebanks
 suitable for linguistic research \cite{samuelsson2007apa}.


Our method is instead based on the idea that similar grammatical
 phenomena in different languages will, if the grammars are correct,
 be given similar grammatical analyses[fn:9], so structural similarity
 in the analyses indicates that those parts of the analyses may be
 linked. How much structural similarity we require in order to link
 two elements is defined as a set of general, language-independent
 constraints. This allows for a more top-down method of phrase
 alignment, the results of which are highly informative to the
 treebank user since we get links not only between true constituents,
 but between functional elements: predicates, arguments and
 adjuncts[fn:12].

Word-alignments or translational dictionaries may be needed to
 automatically disambiguate in cases where the LFG parses do not give
 sufficient information; but the method will perform a large part of
 the alignment job even without /any/ parallel corpus available apart
 from the sentences to be aligned.

The principles and constraints for alignment are discussed in the next
 section, section \ref{SEC:implementation} describes the
 implementation, while section \ref{SEC:discussion} discusses the
 strengths and weaknesses of the method.


* Principles for Phrase Alignment
\label{SEC:principles}

We want our alignment links to be useful for treebank studies; in the
 XPar-project this includes studying the relationship between
 syntactic function and semantic roles across languages, thus the
 principles for alignment (or, constraints on possible alignments)
 have to take this goal into account.  An outline of the principles
 for phrase alignment used in the XPar-project has already been
 formulated \cite[pp.~75--77]{dyvik2009lmp}, this section recounts the
 major points while also delving into some corner cases, and explains
 the relevant LFG-terminology and concepts.


To introduce the relevant LFG-terminology, consider the Norwegian
Nynorsk and English phrases in example \ref{ex:egsov} and their
analyses in figure \ref{fig:simple-links}. This figure shows two
simplified LFG f-structures and c-structures, ready for alignment. The
English word /slept/ is a verb phrase, and its nodes /project/ the
f-structure $g$ (as seen by the \PRED{} value being the `semantic
form' of /slept/, `\textbf{sleep}'). The projection from c-structure
to f-structure, $\phi$, is a many-to-one mapping, and all the nodes S,
VP and V together project $g$. Since the nodes project the same
f-structure, they constitute a /functional domain/. We can see that
they project the same f-structure by the $\ua=\da$ annotations, which
are read as "my f-structure is the same as that of my mother
node". The NP node has $\ua{}\SUBJ{}={}\da$ instead, read as "my
f-structure is the \SUBJ{} of my mother's f-structure"; the NP thus
projects the value of the \SUBJ{} f-structure inside $g$.

#+BEGIN_LaTeX
 \begin{figure}[htp]
    \centering

    \exg. \textbf{eg} \textbf{sov} \label{ex:egsov} \\
     I slept  \\
     `I slept'

    \begin{tikzpicture}
    {\avmoptions{}
     \node(src){
        \begin{avm}
          $f$ \[pred   &  `{\bf{}sove}<\@{1}>'\\
          tense  & pret  \\
	  subj & \@{1} \[pred & `{\bf{eg}}' \] \\
          ... \] 
       \end{avm}
      };
      \node[right of=src, node distance=5cm](trg){
        \begin{avm}
          $g$ \[pred   &  `{\bf{}sleep}<\@{2}>'\\
          tense  & pret  \\
          aspect & simple \\
	  subj & \@{2} \[pred & `{\bf{I}}' \] \\
          ... \]
        \end{avm}
      };
      }
%      \draw[dashed,-] (src.west) .. controls +(-1,3) and +(-1,2) .. node[above,sloped]{$l_f$} (trg.west) ;
%      \draw[-] ($(src.north)-(1,0.3)$) .. controls +(0,1.5) and +(0,1.5) .. node[above,sloped]{$l_p$} ($(trg.north)-(1,0.3)$) ;

      \begin{scope}[shift={(0,-2cm)}]
        \Tree  [.\node(VPs){IP}; [.\proj{\ua{}\SUBJ{}=\da}{NP} \edge[roof]; {eg} ] [.\proj{\ua{}=\da}{I'} [.\proj{\ua{}=\da}{V} \node(sov){sov};  ] ] ]
      \begin{scope}[shift={(5cm,0)}]
        \Tree  [.\node(VPt){S}; [.\proj{\ua{}\SUBJ{}=\da}{NP} \edge[roof]; {I} ] [.\proj{\ua{}=\da}{VP} [.\proj{\ua{}=\da}{V} \node(slept){slept};  ] ] ]
      \end{scope}
      \end{scope}
%      \draw[-] (VPs)..controls +(north:1.5) and +(north:1.5) .. node[above,sloped]{$l_c$} (VPt) ;
%      \draw[dashed,-] (sov)..controls +(north east:1.5) and +(north west:1.5) .. node[above,sloped]{$l_o$} (slept) ;
   \end{tikzpicture}
    
    \caption{Example of simple links between constituents,
   f-structures and words}
   \label{fig:simple-links}
 \end{figure}
#+END_LaTeX

The argument structures of the Norwegian and English verbs are shown
 in their \PRED{} values. Both verbs take one argument; in the figure
 this is represented by an index. By looking up this index, we find
 that the one argument of `\textbf{sove}' is the subject of $f$, with
 `\textbf{eg}' as its \PRED{}; similarly `\textbf{I}', subject of $g$,
 is the only argument of `\textbf{sleep}'. Neither of these subjects
 take any arguments themselves.


The candidates we consider for alignment are c-structure phrases,
 individual words, and \PRED{} elements of f-structures[fn:1].  In
 figure \ref{fig:simple-links}, we can link the \PRED{} elements of
 $f$ and $g$; by doing this we consider their f-structures linked.
 The \PRED{} values of their arguments are also candidates for
 alignment, and in this case there would be no reason not to link
 them. As noted, the S, VP and V nodes in English constitute the
 functional domain of $g$. Similarly IP, I' and V are the functional
 domain of $f$. Since their f-structures are linked, we have reason to
 link nodes from these functional domains. But we only want to link
 nodes if the material they dominate also corresponds: we would not
 want to link IP and S if the NP in Norwegian was linked to something
 that was not dominated by the S in English (or vice versa), since a
 c-structure link means that what is dominated by the linked nodes
 corresponds[fn:2]. However, translations often ommit or add material,
 so an /unlinked/ subordinate node (e.g. an adverbial only expressed
 in one language) should not interfere with the linking of IP and S.

Similarly, on the f-structure level we allow adjuncts (adverbials) to
 remain unlinked; adjuncts differ from arguments mainly in being
 non-obligatory, while arguments /are/ required in order to express a
 certain sense of a predicate. So to link two predicates, we require
 all their arguments to find `linguistically predictable translations'
 (LPT) in the translation, where a source word $W_s$ is
 LPT-correspondent with a target word $W_t$ if ``$W_t$ can in general
 (out of context) be taken to be among the semantically plausible
 translations of $W_s$'' \cite[p.~74]{dyvik2009lmp}. Nouns and
 pronominal forms are also considered LPT-correspondent.

The argument structure of predicates in LFG is ordered, and this order
 typically reflects the semantic role hierarchy (agents being before
 themes, etc.). However, we do not require that linked arguments
 occupy the same positions in the argument structure of their
 predicates, since an English grammar may assign the first argument of
 the verb /like/ to the agent, while a Spanish grammar may assign the
 first argument of the translation, /gustar/, to the theme. As one of
 the goals of the XPar-project is to study the relationship between
 semantic role and syntactic function, the aligner cannot presume that
 the relationship always is straightforward. However, given
 insufficient information, similarity in order may be used to /rank/
 different possible f-structure alignments.


If any of the arguments of two otherwise linkable predicates do not
 have LPT-correspondents among each other, we have evidence that the
 predicates themselves are used to express different propositions. But
 should we allow adjuncts as translations of arguments?  The examples
 in \ref{ex:vedde} are all translations of the same sentence, in
 English, Norwegian Bokmål, Georgian and German. For the four
 different different languages, the grammar writers chose four
 different ways of dividing the participants in the verbal situation
 into arguments and adjuncts[fn:3]. But in this particular
 translation, the predicates clearly express the same proposition.
 Thus we have to allow linking arguments to adjuncts; the monolingual
 evidence which informed the individual grammars may have suggested
 that a certain participant of a verbal situation should be analysed
 as an argument in one language, but as an adjunct in the other -- in
 a particular translation, however, they may still correspond
 semantically.

#+BEGIN_LaTeX
{\avmoptions{}
\ex. \label{ex:vedde}
\a. \textbf{Abrams} \textbf{bet} \textbf{a} \textbf{cigarette} \textbf{with} \textbf{Brown} \textbf{that} \textbf{it} \textbf{was} \textbf{raining.}\\
    $\\\begin{avm}\[pred & `{\bf{}bet}<Abrams, cigarette, rain>'\\
                    adjunct & \{ \rm Browne \}\]\end{avm}\\$
\bg. \textbf{Abrams} \textbf{veddet} \textbf{en} \textbf{sigarett} \textbf{med} \textbf{Browne} \textbf{på} \textbf{at} \textbf{det} \textbf{regnet.}\\
     Abrams bet    a  cigarette with Browne on that it rained.\\
     $\\\begin{avm}\[pred & `{\bf{}bet}<Abrams, cigarette, Browne, rain>' \\
                     adjunct & \{\}\]\end{avm}\\$
\cg. \textbf{abramsi} \textbf{brouns} \textbf{daenajleva} \textbf{sigaret-ze,} \textbf{rom} \textbf{cvimda.} \\
     Abrams.NOM Browne.DAT    bet.PERF   cigarette.DAT-on,  that rained.IMPERF.\\
     $\\\begin{avm}\[pred &  `{\bf{}bet}<Abrams, Browne, rain>'\\
                     adjunct &  \{ \rm cigarette \}\]\end{avm}\\$ 
\dg. \textbf{Abrams} \textbf{hat} \textbf{mit} \textbf{Browne} \textbf{um} \textbf{eine} \textbf{Zigarette} \textbf{gewettet,} \textbf{daß} \textbf{es} \textbf{regnet.}\\
     Abrams has    with Browne about a cigarette.ACC bet, that it rained.\\
     $\\\begin{avm}\[pred & `{\bf{}bet}<Abrams, rain>' \\
                     adjunct & \{ \rm Browne, cigarette \}\]\end{avm}$

}
%\hfill{} (Norwegian Bokmål)\\
#+END_LaTeX

Note: in the f-structures above, some of the arguments/adjuncts are
selected by prepositions, and their \PRED{} will be embedded in the
preposition's f-structure. In this situation, we skip the \PRED{} of
the preposition and consider its object as if there were no
preposition there; this is necessary to align the f-structures in
example \ref{ex:vedde}.

The formal requirements for linking two f-structure \PRED{} elements
$p$ and $q$ (also given in \cite{dyvik2009lmp}) are:
\ex. \label{krav:pred} \a. the word-forms of $p$ and $q$ have LPT-correspondence
     \b. all arguments of $p$ have LPT-correspondence with an argument
     or adjunct of $q$
     \c. all arguments of $q$ have LPT-correspondence with an argument
     or adjunct of $p$
     \d. the LPT-correspondences are one-to-one
     \e. no adjuncts of $p$ are linked to f-structures outside $q$ or
     vice versa

The one-to-one requirement \Last[d] is there to avoid linking two
 near-synonyms in one language into one word in the other language. We
 require all arguments of $p$ to have possible translations among the
 arguments and adjuncts of $q$, but we do not require \Last to be true
 of each argument of $p$; that is, an argument of $p$ may remain
 unlinked on the f-structure level. 
As mentioned, for adjuncts of $p$ we do not even require that they
 have LPT-correspondence with arguments/adjuncts of $q$, or vice
 versa, but \Last[e] ensures that they are not /linked/ outside of
 their predicates, which would imply that $p$ and $q$ did not contain
 corresponding linked material.

In order to link two c-structure nodes, \cite[p.~77]{dyvik2009lmp}
 defines the term /linked lexical nodes/, $LL$, where $LL(n)$ is the
 set of nodes dominated by $n$ which are word-linked. To link $n_s$
 and $n_t$ (whose projected f-structures must be linked), all nodes in
 $LL(n_s)$ must be linked to nodes in $LL(n_t)$. Unlinked nodes
 dominated by $n_s$ or $n_t$ are not an obstacle to linking these
 nodes. Thus in in figure \ref{fig:simple-links}, if the NP nodes are
 linked, we may link IP and S.


The sentences in \ref{ex:roboter}, with c-structures in figure
 \ref{fig:roboter}, illustrate a much more complex
 situation[fn:16]. Here the Norwegian I' and lower Georgian IP node
 may not be linked since the IP node dominates /robotebze/, linked to
 /roboter/, which is outside the nodes dominated by I'[fn:6].
 Georgian being a pro-drop language, the argument expressed by /de/ in
 Norwegian does not have to be overtly expressed in Georgian, so there
 is no c-structure link for this word[fn:5].  But by the criterion
 above we can still link the upper IP nodes, as they dominate the same
 sets of linked lexical nodes; the adjunct /gzaSi/ (``on the way'') is
 a translators addition only seen in the Georgian text, and remains
 unlinked both on c-structure and f-structure level, it does not stop
 linking the IP nodes.

    \ex. \label{ex:roboter} \ag. \textbf{roboter} \textbf{hadde} \textbf{de} \textbf{snakket} \textbf{om} \\
     robots had they talked about  \\
     `They had talked about \emph{robots}'
     \bg. \textbf{gza-Si} \textbf{roboteb-ze} \textbf{laparakobdnen} \\
     way.DAT-to robots.DAT-on talked.3PL \\
     `On the way, they had talked about robots'

#+BEGIN_LaTeX
    \begin{figure}[htp]
    \centering     
      \begin{tikzpicture}
      \tikzset{level distance=1.4cm,sibling distance=0.1pt}
      \Tree  [.\node(IPs){IP};  [.\node(roboter){\proj{\ua{}\TOPIC{}=\da}{NP}}; \edge[roof]; {roboter} ]
                                [.\node(I's){\proj{\ua=\da}{I'}};
                                        [.\node(Is){\proj{\ua=\da}{I}}; {hadde} ]
                                        [.\node(Ss){\proj{\ua=\da}{S}};
					[.\node(SUBJs){\proj{\ua\SUBJ{}=\da}{NP}}; \edge[roof]; {de} ]
                                           [.\node(VPs){\proj{\ua{}\XCOMP{}=\da}{VP}};  
                                             [.\node(Vs){\proj{\ua=\da}{V}}; {snakket} ]
					     [.\node(om){\proj{}{PP}}; \edge[roof]; {om} ]
  ] ] ] ]
          \begin{scope}[shift={(2.7in,0in)}]
      \Tree  [.\node(IPt){IP};  [.\node(PPt){\proj{\da$\in$\ua{}\ADJUNCT{}}{PP}}; \edge[roof]; {gzaSi} ]
                                [.\node(IP2t){\proj{\ua=\da}{IP}};
                                        [.\node(roboteb){\proj{\da$\in$\ua{}\ADJUNCT{}}{PP}}; \edge[roof]; {robotebze} ]
                                        [.\node(I't){\proj{\ua=\da}{I'}}; \edge[roof]; {laparakobdnen} ]
  ] ]
    \end{scope}
  \draw[dashed,-] (I's)..controls +(north:2) and +(north:3) .. node[midway,sloped]{$\times$} (IP2t) ;
  \draw[-] (roboter)..controls +(north east:2.5) and +(west:2.0) ..  (roboteb) ;
%  \draw[dashed,-] (VPs)..controls +(east:1) and +(west:1) .. node[above,sloped]{?} (I't) ;
    
    \end{tikzpicture}
       \caption{C-structure links must dominate the same set of links}
       \label{fig:roboter}
      \end{figure}
#+END_LaTeX

By the above criterion, we may also link the Norwegian VP and Georgian
 I' nodes, since they dominate the same linked lexical nodes,
 /laparakobdnen/ and /snakket/. However, /laparakobdnen/ specifies a
 non-overt third person plural subject, while /snakket/ does not. On
 the f-structure level, this pro-subject is linked to the Norwegian
 subject (/de/ in the c-structure); a treebank user may want to
 exclude the link between the VP and I' nodes because of this
 discrepancy. Formally, we can exclude this kind of link by adding to
 $LL(n)$ any linked f-structure arguments (of the f-structure
 projected by $n$) that are not overtly expressed[fn:7].

Several nodes may have equal $LL$, thus the c-structure links are
 often /many-to-many/. In addition, the f-structure \PRED{} links are
 not always one-to-one, but this is a slightly more complex situation.

The f-structures of figure \ref{fig:f-roboter} need a many-to-many
 \PRED{} link from /hadde/ and /snakket/ to /laparakobdnen/, since the
 current XPar grammars analyse /laparakobdnen/ (they.talked) as a
 single predicate, while treating /hadde/ (the perfective auxiliary)
 and /snakket/ (talked) as two separate predicates. One might argue
 that then such phenomena should be analysed similarly, but as it is
 the goal of the aligner to help in discovering cross-language
 differences, all the while assuming that similar grammatical
 phenomena have similar grammatical analyses, grammars cannot be
 changed just to make the alignment easier --- we have to treat this as
 a many-to-one \PRED{} link[fn:10].

In order to many-to-one-link $p$ with $q$ and $a_q$ on the f-structure
 level, where $a_q$ is an argument of $q$, the same requirements as
 \ref{krav:pred} need to be fulfilled, but with the following
 difference: the argument lists of $q$ and $a_q$ are merged (as are
 their adjunct lists), with $a_q$ not appearing in this list. 

#+BEGIN_LaTeX
\begin{figure}[htp]
\centering
\begin{tikzpicture}
    {\avmoptions{}
     \node(src){
        \begin{avm}
    $q$ \[pred    &       `{\bf{}perf}<\@{1}>\@{2}'\\
	  subj    & \@{2} \\
	  topic   & \@{3} \\
	  xcomp   & \@{1} \[pred & `{\bf{snakke*om<\@{2},\@{3}>}}' \\
	                    subj & \@{2} \[pred & `{\bf{de}}' \] \\
                            obj  & \@{3} \[pred & `{\bf{robot}}' \]
		 	  \]
        \]
       \end{avm}
      };
      \node[right of=src, node distance=6.5cm](trg){
        \begin{avm}
    $p$ \[pred    &       `{\bf{laparaki}}<\@{4}>'\\
	  subj    & \@{4} \[pred & `{\bf{pro}}' \] \\
	  adjunct & \{ \[pred & `{\bf{Si<\@{5}>}}' \\
                         obj  & \@{5} \[pred & `{\bf{gza}}' \] \],\\
		       \[pred & `{\bf{ze<\@{6}>}}' \\
                         obj  & \@{6} \[pred & `{\bf{roboti}}' \] \] \}
        \]
        \end{avm}
      };
      }
\end{tikzpicture}
\caption{F-structure many-to-one link from \textbf{perf} and
\textbf{snakke*om} to \textbf{laparaki}.}
\label{fig:f-roboter}
\end{figure}
#+END_LaTeX

So when attempting to link /hadde/ ($q$) and /snakket/ ($a_q$) with
 /laparakobdnen/ ($p$), we merge the argument lists of $q$ and its
 \XCOMP{} argument, excluding the \XCOMP{} itself, i.e.
 $\{\ind{1},\ind{2}\}\bigcup\{\ind{2},\ind{3}\}-\{\ind{1}\}=\{\ind{2},\ind{3}\}$
 (there are no adjuncts on the Norwegian side). Now we can link
 /laparakobdnen/ with /hadde/ and /snakket/ by matching /de/ (\ind{2})
 with the pro-element (\ind{4}), and /robot/ (\ind{3}) with
 /roboti/ (\ind{6}). 


The next section discusses the current implementation of these
principles, while section \ref{SEC:discussion} compares the possible
merits of this method with other alignment methods.


* Implementation
\label{SEC:implementation}

This section covers a work-in-progress implementation of the above
 alignment principles[fn:4]. The program takes as input LFG-analyses
 of two sentence which we for independent reasons consider as
 translations of each other. The analyses must be disambiguated and in
 the XLE-format[fn:8]. One may optionally supply
 information about which word-translations are considered LPT (e.g.
 from automatic word-alignments or translational dictionaries).

The program begins by linking f-structures, where an f-structure
 /alignment/ is a set of /links/ between individual f-structures. The
 result of linking on this level may be ambiguous. Since there are
 often several ways of linking arguments and adjuncts given
 insufficient LPT-information, we may end up with several possible
 f-structure alignments.

The f-structure aligner, algorithm \ref{algo:f-align}, starts with the
 two outermost f-structures projected by LPT-correspondent words. The
 helper $argalign$ returns all possible ways of matching all
 arguments of the source \PRED{} with LPT-correspondent
 arguments/adjuncts of the target \PRED{} and vice versa. For each of
 these possibilities, we recursively try to align the matched
 arguments/adjuncts[fn:11], storing these possible sub-alignments in a
 table since solutions may overlap.

#+BEGIN_LaTeX
      \SetKwComment{Comment}{ // }{}
     \SetKwInOut{Input}{usage}
  
     \begin{algorithm}[]
      \caption{f-align($F_s$, $F_t$)}
      \label{algo:f-align}
      
      $alignments \gets \emptyset$  \;
      \ForAll{argperm in argalign($F_s$, $F_t$) with $p \gets \emptyset$} {
         \ForAll{$A_s$, $A_t$ in argperm} {
           \lIf{not(atab[$A_s$,$A_t$])} {
           atab[$A_s$,$A_t$] $\gets$ f-align($A_s$, $A_t$)\;
           }
          \lIf{atab[$A_s$,$A_t$]}{add atab[$A_s$,$A_t$] to $p$\;}
          \lElse{add $(A_s, A_t)$ to $p$} \Comment*[r]{only LPT-correspondence}
        }
        add $p$ to $alignments$ \;
        \ForAll{adjperm in adjalign(argperm, $F_s$, $F_t$)} {
          $a \gets$ copy-of($p$) \Comment*[r]{optional adjunct links}
	  \Comment{loop as above, add aligned adj-pairs to $a$}
          add $a$ to $alignments$ \;
        } % adjperm in adjalign
       } % argperm in argalign
       \Comment{loop through adjalign if no arguments exist}
       \lIf {$alignments=\emptyset$}{ call f-align for each
      possible pred-arg merge \; }
       \lElse{ \Return $((F_s, F_t), alignments)$ \; }
       \end{algorithm}    
    
#+END_LaTeX

If we find no way of fulfilling the requirements in \ref{krav:pred}
 for $F_s$ and $F_t$, we may try many-to-one links by merging argument
 lists as discussed in the previous section. Since this is not tried
 until there are no other possibilities, solutions involving
 many-to-one links of \PRED{} elements are implicitly ranked lower
 than those where we can assume that translations corresponded better
 (a natural assumption since the sentences were aligned in the first
 place).

Since f-align may give several solutions, we rank the
 f-alignments. There are several possible ranking criteria; as
 mentioned above we use similarity in order of arguments to rank
 different possible f-structure alignments, when the LPT-information
 is not sufficient.

A single f-structure alignment is sent to the c-structure aligner,
 which by following the principles of section \ref{SEC:principles}
 always finds a single, unambiguous c-structure alignment (the
 different possible ways of calculating $LL$ noted above are
 considered a user-option). Finding the c-structure alignment for a
 single f-structure alignment involves first finding the $LL$ for each
 node, where $LL(n)$ is the union of $LL(m)$ for all $m$ dominatd by
 of $n$, and then creating many-to-many links between those nodes that
 have the same $LL$. The many-to-many links here are the constituent
 alignment.

* Discussion and outlook
\label{SEC:discussion}

The current implementation is, as mentioned, a work in progress (in
 particular, it does not yet handle f-structure links that are not
 one-to-one), making it difficult to do a complete evaluation at this
 point[fn:15]. However, tests conducted on a set of example sentences,
 chosen to illustrate a wide variety of grammatical phenomena, seem
 promising.

Of course, the alignments will only be as good as the grammatical
 analyses that gave rise to them, so this is an important possible
 source of errors. Building high-quality, wide-coverage LFG grammars
 requires manual work that could be avoided if a large enough corpus
 is available.

However, a top-down method of alignment may be quite useful for
 language pairs with few parallel resources, where there exist LFG
 grammars for the languages. For a language pair such as
 Norwegian-Georgian, it is difficult to obtain a parallel corpus large
 enough to create high quality phrase alignments by purely
 corpus-based methods, not only because of the marginalisation of the
 languages, but also because of the productive morphology of Georgian.
 By taking advantage of structural similarity in the LFG analyses of
 parallel sentences, the need for huge corpora is
 lessened[fn:14]. Given some manual intervention in selecting between
 ambiguous alignments (and a suitable interface[fn:13]), not even a
 translational dictionary is needed.








\bibliography{master}





* COMMENT foo
    
      \begin{algorithm}[]
      \caption{argalign-p($args_s$, $adjs_s$, $args_t$, $adjs_t$)}
      \label{algo:argalign-p}
    
      \Input{Kalt av argalign slik: \\ argalign-p(arguments($F_s$),
      adjuncts($F_s$), arguments($F_t$), adjuncts($F_t$))}
      \BlankLine
      
     $a \gets \emptyset$\;
     \uIf{$args_s$} {
           $s \in args_s$\;
           \ForAll{$t \in args_t$ \textbf{where} LPT($s$,$t$)} {
               \lForAll{$p \in$ argalign-p($args_s-\{s\}$, $adjs_s$, $args_t-\{t\}$,$adjs_t$)}{
  add $\{(s,t)\} \bigcup p$ to $a$\;
             }
            }
           \ForAll{$t \in adjs_t$ \textbf{where} LPT($s$,$t$)} {
               \lForAll{$p \in$ argalign-p($args_s-\{s\}$, $adjs_s$, $args_t$,$adjs_t-\{t\}$)}{
  add $\{(s,t)\} \bigcup p$ to $a$\;
                }
           }
             \Return $a$\;
         }
          \uElseIf{$args_t$} {
            \uIf{$adjs_s$}{
                $s \in adjs_s$\;
           \ForAll{$t \in args_t$ \textbf{where} LPT($s$,$t$)} {
               \lForAll{$p \in$ argalign-p($args_s$, $adjs_s-\{s\}$, $args_t-\{t\}$,$adjs_t$)}{
  add $\{(s,t)\} \bigcup p$ to $a$\;
             }
            }
             \Return $a$\;
        }\uElse{
              \Return $\emptyset$  \Comment*[l]{Fail}
            }
          }
        \uElse {
          \Return \{$\emptyset$\} \Comment*[l]{End}
        }     
      \end{algorithm}

* Footnotes

[fn:1] We could consider aligning other f-structure elements, but only
 \PRED{} elements are sure to exist in both languages, while
 grammatical features such as \ASPECT{} might not exist in both
 languages, or be possible to link in a one-to-one-manner.

[fn:2] Even if IP and S could not be linked, we could still link I'
 and VP, as these dominate the same linked material.

[fn:3] The \PRED{} names in these f-structures have been translated to
 simplify the example. The analyses come from the grammars of the
 ParGram-project \cite{butt2002pgp}.

[fn:4] All code available from http://example.com under the GNU
       General Public License, version 2 or later, along with some
       example input parses.

[fn:5] The pro-subjects will be linked in f-structure, however. 

[fn:6] The notation $\da\in\ua\ADJUNCT{}$ reads "my f-structure is a
 member of the set of adjuncts of my mother's f-structure" (a
 predicate may have only one subject, but an arbitrary number of
 adjuncts). Figure \ref{fig:roboter} is another example of phrases
 analysed as adjuncts in one language corresponding to phrases
 analysed as arguments in another language.

[fn:7] We cannot add just any /overtly/ expressed argument to $LL$, as
 that would let us link the Norwegian I' and the Georgian IP node.

[fn:8] http://www2.parc.com/isl/groups/nltt/xle/doc/xle.html

[fn:9] Analysing similar phenomena in similar ways is a central
 guideline for grammar writers in the XPar-project, as well as of the
 overarching ParGram-project \cite{butt2002pgp}.

[fn:10] Although in this case we might be able to align only the
 content verbs /hadde/ and /laparakobdnen/ by simply excluding
 auxiliary verbs from f-structure alignment, as with prepositions,
 there are other situations where we cannot avoid many-to-many links
 in a non-arbitrary fashion, e.g. lexical causatives linking to
 periphrastic causatives, argument incorporation, etc.

[fn:11] We allow \PRED{} elements $p$ and $q$ to be linked even though
 some of their arguments cannot be recursively \PRED{}-linked, as long
 as the requirement for word-level LPT-correspondence is fulfilled.

[fn:12] In LFG these functional elements may even span discontiguous
 constituents.

[fn:13] The interface developed in \cite{rosen2009lpt} is in the
 process of being extended for alignment selection.

[fn:14] Another issue is that using N-gram alignments created from
 corpora outside the domain of the treebank text (e.g. in order to
 increase recall) may hurt precision severely
 \cite{samuelsson2007apa}.

[fn:15] Additionally, the program expects disambiguated analyses, and
 many sentences in the larger test sets have not seen manual
 disambiguation yet.

[fn:16] Taken from a book translation, but the Norwegian sentence is
 topicalised for this example.
